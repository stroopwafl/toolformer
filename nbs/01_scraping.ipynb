{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0be4ce6-e51a-49a9-bc40-e8a10b8cfe55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b006e1-e168-4717-b249-44a8b0b1ddc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import os\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from PIL import Image\n",
    "import requests\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.common.exceptions import ElementClickInterceptedException\n",
    "import re\n",
    "import urllib\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import fastcore.all as fc\n",
    "from fastcore import docments\n",
    "from datasets import load_dataset\n",
    "import math\n",
    "import shutil\n",
    "from unstably_diffused.core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e61b4d-2dda-447b-af67-7d4460a0a448",
   "metadata": {},
   "source": [
    "# Scraping\n",
    "\n",
    "This notebook contains a series of tools for scraping Unsplash with Selenium. Scraping is particularly unfun and this makes it a little less soul destroying. It includes functions that support the full pipeline from scraping images and descriptive text to creating and uploading a hugging face dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6710cb-c87d-4c5f-b1f4-21b404dbb83c",
   "metadata": {},
   "source": [
    "## Unsplash Scraper\n",
    "\n",
    "Unsplash has a lot of images and helpfully has good alt text for most images, which can be used as a description. We can use Selenium to identify these elements and extract them. Using Selenium means we can move much faster than we can using the Unsplash API â€” the free/unregistered version only allows 50 requests an hour. If you are building large datasets, this means it will take a lifetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c964fed8-3cca-4c23-b3c2-dea45ccf1aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class UnsplashScraper():\n",
    "    def __init__(\n",
    "        self, \n",
    "        search_term: str, # term to search on Unsplash\n",
    "        save_path: str, # Root folder to save images and descriptions\n",
    "        alt: bool=True, # If true, collects the alt text and saves to a txt file\n",
    "        crop=True, # If crop, uses crop_512 function\n",
    "        desc_front_decorator: str=None, # Optional text to add in front of scraped alt text\n",
    "        desc_back_decorator: str=None, # Optional text to add to end of scraped alt text\n",
    "    ):\n",
    "        fc.store_attr()\n",
    "        self.slug = \"-\".join(search_term.split())\n",
    "        self.url = f\"https://unsplash.com/s/photos/{self.slug}\"\n",
    "        self.driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "        self.driver.get(self.url)\n",
    "        self.it = 0\n",
    "    \n",
    "    def scrape(self):\n",
    "        elements = self.get_elements()\n",
    "        self.descs = [el.get_attribute('alt') for el in elements]\n",
    "        self.img_links = [el.get_attribute('src') for el in elements]\n",
    "        self.get_images()\n",
    "        self.get_descriptions()\n",
    "        \n",
    "    def get_images(self):\n",
    "        os.makedirs(f'{self.save_path}/img', exist_ok=True)\n",
    "        for i, l in tqdm(enumerate(self.img_links), total=len(self.img_links)):\n",
    "            try:\n",
    "                img = download_img_from_url(l)\n",
    "                if self.crop: \n",
    "                    crop = crop_square(img).resize((512, 512))\n",
    "                    crop.save(f'{self.save_path}/img/{i}_{self.slug}.png')\n",
    "                else:\n",
    "                    img.save(f'{self.save_path}/img/{i}_{self.slug}.png')\n",
    "            except: self.it = i\n",
    "                \n",
    "    def get_descriptions(self):\n",
    "        fnames = [i for i in os.listdir(self.save_path)]\n",
    "        self.desc_fname, file_count_list = 0, []\n",
    "        for i in fnames: \n",
    "            if \"descriptions\" in i:\n",
    "                try:\n",
    "                    h = int(re.search('([\\d]+)', i).groups()[0])\n",
    "                    file_count_list.append(h)\n",
    "                except: pass\n",
    "        if len(file_count_list) != 0: self.desc_fname = max(file_count_list) + 1\n",
    "        with open(f'{self.save_path}/descriptions_{self.desc_fname}.txt', 'w') as file:\n",
    "            if self.desc_front_decorator: d = self.desc_front_decorator + d\n",
    "            if self.desc_back_decorator: d = d + self.desc_back_decorator\n",
    "            for d in self.descs: file.write(d + '\\n')\n",
    "            \n",
    "    def make_dataframe(self):\n",
    "        if '.ipynb_checkpoints' in [i for i in os.listdir(f'{self.save_path}/img')]:\n",
    "            shutil.rmtree(f'{self.save_path}/img/.ipynb_checkpoints')\n",
    "        im_fnames = [i for i in os.listdir(f'{self.save_path}/img')]\n",
    "        file = open(f'{self.save_path}/descriptions_{self.desc_fname}.txt')\n",
    "        descs = file.readlines()\n",
    "        ns = [int(re.search(r\"([\\d]+)\", nm).groups()[0]) for nm in im_fnames]\n",
    "        df = pd.DataFrame({\n",
    "            \"file_name\": im_fnames,\n",
    "            'ns': ns\n",
    "        })\n",
    "        df = df.sort_values('ns', ascending=True)\n",
    "        df.drop(columns='ns', inplace=True)\n",
    "        df['description'] = descs\n",
    "        return df\n",
    "        \n",
    "    def get_elements(self): return self.driver.find_elements(By.XPATH, '//div[contains(@class, \"rJ2xz bYpwS U8eXG M5vdR\")]/div/div/div/figure/div/div/div/div/a/div/div[contains(@class, \"MorZF\")]/img')\n",
    "    def zip_elements(self): return zip(self.img_links, self.descs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488872ac-e6c2-4923-97f6-5f01e146a49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def make_dataset(df, img_path, push_hub_path=None):\n",
    "    df.to_csv(f'{path}/img/metadata.csv', index=False)\n",
    "    dataset = load_dataset(img_path, split=\"train\")\n",
    "    if push_hub_path is not None: dataset.push_to_hub(push_hub_path)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb42a017-45fe-4b47-868c-f17445a9458f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def download_img_from_url(url):\n",
    "    request = urllib.request.Request(url)\n",
    "    return Image.open( urllib.request.urlopen(request) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0e29b3-6caf-41be-869e-bd11cea622be",
   "metadata": {},
   "source": [
    "## Cropping and resizing\n",
    "\n",
    "Most Unsplash images are in odd shapes. To work well with Stable Diffusion, it is useful to crop images down to 512x512."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f896437-c3ab-4837-97ac-b354b7c649d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def crop_square(img):\n",
    "    \"\"\"\n",
    "        Takes an image, either portrait or landscape, and crops the middle 512x512\n",
    "        portion. Does NOT do anything fancy like face recognition.\n",
    "    \"\"\"\n",
    "    width, height = img.size   # Get dimensions\n",
    "    delta = width-height\n",
    "    delta_ = math.sqrt(delta**2)\n",
    "    \n",
    "    top=0 \n",
    "    bottom=height \n",
    "    left=0\n",
    "    right = width\n",
    "    \n",
    "    if delta < 0:\n",
    "        top = delta_ // 2\n",
    "        bottom = (height - (delta_ // 2))\n",
    "    elif delta > 0:\n",
    "        left = delta_ // 2\n",
    "        right = (width - (delta_ // 2))\n",
    "    else: pass\n",
    "    \n",
    "    return img.crop((left, top, right, bottom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f4cc27-124a-4cbe-b462-4b4950d9cda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9bf3bc-c1f9-4780-8d0f-3aa9ae4bcc40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
